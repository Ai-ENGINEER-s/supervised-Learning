{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB1 : Implementation manuelle de la regression lineaire multiple\n",
    "\n",
    "### Dans cette lab l'objectif est de coder nous meme notre modèle de la regression lineaire Multiple sans passer par une bibliothèque tierce . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 8863704678.928347\n",
      "Iteration 1000: Cost 1374661096.4474719\n",
      "Iteration 2000: Cost 373285054.99258614\n",
      "Iteration 3000: Cost 238459804.5686218\n",
      "Iteration 4000: Cost 220256290.72399595\n",
      "Iteration 5000: Cost 217795055.70822418\n",
      "Iteration 6000: Cost 217461793.4826385\n",
      "Iteration 7000: Cost 217416533.58450592\n",
      "Iteration 8000: Cost 217410341.00364435\n",
      "Iteration 9000: Cost 217409477.55370894\n",
      "Prediction for [2030    4]: [144058.29250012]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Fonction coût pour la régression linéaire (Mean Squared Error)\n",
    "def compute_cost_linear_regression(x, y, w, b):\n",
    "    m = x.shape[0]  # Nombre d'exemples d'entraînement\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b  # Prédiction pour l'exemple i\n",
    "        err = f_wb_i - y[i]  # Erreur\n",
    "        cost += err ** 2\n",
    "    cost /= (2 * m)\n",
    "    return cost \n",
    "\n",
    "# Descente de gradient pour calculer les gradients de w et b\n",
    "def compute_gradient_descent(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    n = len(w)\n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0.0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b\n",
    "        err = f_wb_i - y[i]\n",
    "        \n",
    "        for j in range(n):\n",
    "            dj_dw[j] += err * x[i, j]  # Gradient par rapport à w_j\n",
    "        dj_db += err  # Gradient par rapport à b\n",
    "\n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "    return dj_dw, dj_db\n",
    "\n",
    "# Descente de gradient pour ajuster w et b\n",
    "def linear_gradient_descent(x, y, w_in, b_in, alpha, num_iters):\n",
    "    w = copy.deepcopy(w_in)  # Copie des poids\n",
    "    b = b_in\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        # Calcul du coût actuel\n",
    "        cost = compute_cost_linear_regression(x, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Calcul des gradients\n",
    "        dj_dw, dj_db = compute_gradient_descent(x, y, w, b)\n",
    "\n",
    "        # Mise à jour des paramètres\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "\n",
    "    return w, b, cost_history\n",
    "\n",
    "# Fonction de prédiction\n",
    "def predict(x, w, b):\n",
    "    return np.dot(x, w) + b\n",
    "\n",
    "# Fonction pour normaliser manuellement les features\n",
    "def manual_normalization(x):\n",
    "    mean = np.mean(x, axis=0)  # Moyenne des colonnes\n",
    "    std = np.std(x, axis=0)  # Écart-type des colonnes\n",
    "    return (x - mean) / std, mean, std  # Retourne les données normalisées, la moyenne et l'écart-type\n",
    "\n",
    "# Lire le fichier CSV\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extraire les features et la cible\n",
    "x_train = data[['SqFt', 'Bedrooms']].values \n",
    "y_train = data.get('Price').values \n",
    "\n",
    "# Normaliser manuellement les données d'entrée (features)\n",
    "x_train_scaled, mean, std = manual_normalization(x_train)\n",
    "\n",
    "# Initialisation des paramètres\n",
    "w_init = np.array([0.5, 1])  # Ajustez en fonction du nombre de variables explicatives\n",
    "b_init = 0.5\n",
    "alpha = 0.001  # Taux d'apprentissage\n",
    "iterations = 10000\n",
    " \n",
    "# Entraînement du modèle\n",
    "w_final, b_final, cost_hist = linear_gradient_descent(x_train_scaled, y_train, w_init, b_init, alpha, iterations)\n",
    "\n",
    "# Prédiction pour un nouvel exemple (ex. 2030 SqFt, 4 chambres)\n",
    "x_test = np.array([[2030, 4]])\n",
    "\n",
    "# Normaliser manuellement l'exemple de test\n",
    "x_test_scaled = (x_test - mean) / std\n",
    "y_pred = predict(x_test_scaled, w_final, b_final)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de scikit-learn pour comparer les resultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for [2030    4]: [144059.32018322]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Lire le fichier CSV\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extraire les features et la cible\n",
    "x_train = data[['SqFt', 'Bedrooms']].values\n",
    "y_train = data['Price'].values\n",
    "\n",
    "# Normalisation des données avec scikit-learn\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Entraînement du modèle de régression linéaire avec scikit-learn\n",
    "model = LinearRegression()\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prédiction pour un nouvel exemple (ex. 2030 SqFt, 4 chambres)\n",
    "x_test = np.array([[2030, 4]])\n",
    "\n",
    "# Normalisation de l'exemple de test\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Lineaire Simple \n",
    "\n",
    "#### implementation manuelle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 8863718753.865515\n",
      "Iteration 1000: Cost 248628341.22142452\n",
      "Iteration 2000: Cost 248628325.164993\n",
      "Iteration 3000: Cost 248628325.16499305\n",
      "Iteration 4000: Cost 248628325.1649929\n",
      "Iteration 5000: Cost 248628325.1649929\n",
      "Iteration 6000: Cost 248628325.1649929\n",
      "Iteration 7000: Cost 248628325.1649929\n",
      "Iteration 8000: Cost 248628325.1649929\n",
      "Iteration 9000: Cost 248628325.1649929\n",
      "Prediction for [2030]: [132468.29612393]\n"
     ]
    }
   ],
   "source": [
    "# using one feature instead many feature linear regression manually coded : \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Cost function for linear regression (Mean Squared Error)\n",
    "def compute_cost_linear_regression(x, y, w, b):\n",
    "    m = x.shape[0]  # Number of training examples\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b  # Prediction for example i\n",
    "        err = f_wb_i - y[i]  # Error\n",
    "        cost += err ** 2\n",
    "    cost /= (2 * m)\n",
    "    return cost \n",
    "\n",
    "# Gradient descent to calculate gradients of w and b\n",
    "def compute_gradient_descent(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    dj_dw = 0.0\n",
    "    dj_db = 0.0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b\n",
    "        err = f_wb_i - y[i]\n",
    "        dj_dw += err * x[i]  # Gradient with respect to w\n",
    "        dj_db += err  # Gradient with respect to b\n",
    "\n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "    return dj_dw, dj_db\n",
    "\n",
    "# Gradient descent to adjust w and b\n",
    "def linear_gradient_descent(x, y, w_in, b_in, alpha, num_iters):\n",
    "    w = copy.deepcopy(w_in)  # Copy weights\n",
    "    b = b_in\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        # Calculate the current cost\n",
    "        cost = compute_cost_linear_regression(x, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Calculate the gradients\n",
    "        dj_dw, dj_db = compute_gradient_descent(x, y, w, b)\n",
    "\n",
    "        # Update parameters\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "\n",
    "    return w, b, cost_history\n",
    "\n",
    "# Prediction function\n",
    "def predict(x, w, b):\n",
    "    return np.dot(x, w) + b\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extract the single feature and the target\n",
    "x_train = data[['SqFt']].values  # Use only one feature\n",
    "y_train = data['Price'].values\n",
    "\n",
    "# Normalization manually\n",
    "mean = np.mean(x_train)\n",
    "std = np.std(x_train)\n",
    "x_train_scaled = (x_train - mean) / std\n",
    "\n",
    "# Initialize parameters\n",
    "w_init = np.array([0.5])  # Adjust for one feature\n",
    "b_init = 0.5\n",
    "alpha = 0.01  # Learning rate\n",
    "iterations = 10000\n",
    "\n",
    "# Train the model\n",
    "w_final, b_final, cost_hist = linear_gradient_descent(x_train_scaled, y_train, w_init, b_init, alpha, iterations)\n",
    "\n",
    "# Prediction for a new example (e.g., 2030 SqFt)\n",
    "x_test = np.array([[2030]])\n",
    "\n",
    "# Normalize the test example\n",
    "x_test_scaled = (x_test - mean) / std\n",
    "y_pred = predict(x_test_scaled, w_final, b_final)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression lineaire implemnentation avec scikit-learn pour comparer les resultats \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for [2030]: [132468.29612393]\n"
     ]
    }
   ],
   "source": [
    "# one feature using scikit-learn library \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extract the single feature and the target\n",
    "x_train = data[['SqFt']].values  # Use only one feature\n",
    "y_train = data['Price'].values\n",
    "\n",
    "# Normalization with scikit-learn\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Train the linear regression model with scikit-learn\n",
    "model = LinearRegression()\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prediction for a new example (e.g., 2030 SqFt)\n",
    "x_test = np.array([[2030]])\n",
    "\n",
    "# Normalize the test example\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## regression lineaire Multiple implementing by myself \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_functionLR(x , y , w, b):\n",
    "\n",
    "    m = x.shape[0]\n",
    "\n",
    "    \n",
    "\n",
    "    cost =0.0\n",
    "\n",
    "    for i in range(m):\n",
    "\n",
    "         model = np.dot(x[i], w) +b \n",
    "\n",
    "         predic = model - y[i]\n",
    "\n",
    "         err = predic **2 \n",
    "\n",
    "         cost+= err \n",
    "\n",
    "    return cost \n",
    "\n",
    "\n",
    "def computeGradientLR(x , y , w , b ):\n",
    "     \n",
    "\n",
    "        m = x.shape[0]\n",
    "\n",
    "        n = len(w)\n",
    "\n",
    "        dj_dw = np.zeros(n)\n",
    "\n",
    "        dj_db = 0.0\n",
    "\n",
    "\n",
    "        for i  in range(m):\n",
    "            \n",
    "\n",
    "            model = np.dot(x[i], w ) +b \n",
    "\n",
    "            predict = model - y[i]\n",
    "\n",
    "            for j in range(n):\n",
    "                dj_dw[j]+= predict * x[i, j]\n",
    "            dj_db+=predict\n",
    "        dj_dw /= m \n",
    "        dj_db /=m \n",
    "\n",
    "\n",
    "        return dj_dw , dj_db\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gradienDescentLR(x , y , w_in , b_in , alpha , num_iterations ):\n",
    "     \n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "\n",
    "    j_cost_history = [] \n",
    "\n",
    "    for i in range(num_iterations): \n",
    "        \n",
    "\n",
    "        dj_dw , dj_db = computeGradientLR(x , y , w ,b)\n",
    "\n",
    "        # mise a jour des parametres \n",
    "\n",
    "        w = w- alpha * dj_dw\n",
    "\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        cost = compute_functionLR(x , y , w , b)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            \n",
    "\n",
    "            j_cost_history.append(cost)\n",
    "\n",
    "            print(f\"{i} : {cost}\")\n",
    "    return w , b , j_cost_history\n",
    "\n",
    "\n",
    "\n",
    "def predictLR(x , w ,b): \n",
    "     \n",
    "\n",
    "     return np.dot(x , w) + b \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 2264649020801.784\n",
      "1000 : 351319263316.382\n",
      "2000 : 95481122087.11298\n",
      "3000 : 61034935657.95785\n",
      "4000 : 56384154278.26294\n",
      "5000 : 55755337213.97192\n",
      "6000 : 55670192409.07889\n",
      "7000 : 55658628954.699646\n",
      "8000 : 55657046793.65668\n",
      "9000 : 55656826181.8757\n",
      "Prediction for [2030    4]: [144058.29250012]\n"
     ]
    }
   ],
   "source": [
    "# Lire le fichier CSV\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extraire les features et la cible\n",
    "x_train = data[['SqFt', 'Bedrooms']].values \n",
    "y_train = data.get('Price').values \n",
    "\n",
    "# Normaliser manuellement les données d'entrée (features)\n",
    "x_train_scaled, mean, std = manual_normalization(x_train)\n",
    "\n",
    "# Initialisation des paramètres\n",
    "w_init = np.array([0.5, 1])  # Ajustez en fonction du nombre de variables explicatives\n",
    "b_init = 0.5\n",
    "alpha = 0.001  # Taux d'apprentissage\n",
    "iterations = 10000\n",
    " \n",
    "# Entraînement du modèle\n",
    "w_final, b_final, cost_hist = gradienDescentLR(x_train_scaled, y_train, w_init, b_init, alpha, iterations)\n",
    "\n",
    "# Prédiction pour un nouvel exemple (ex. 2030 SqFt, 4 chambres)\n",
    "x_test = np.array([[2030, 4]])\n",
    "\n",
    "# Normaliser manuellement l'exemple de test\n",
    "x_test_scaled = (x_test - mean) / std\n",
    "y_pred = predictLR(x_test_scaled, w_final, b_final)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 2225223284309.601\n",
      "1000 : 63648855270.88682\n",
      "2000 : 63648851242.23817\n",
      "3000 : 63648851242.23819\n",
      "4000 : 63648851242.23818\n",
      "5000 : 63648851242.23818\n",
      "6000 : 63648851242.23818\n",
      "7000 : 63648851242.23818\n",
      "8000 : 63648851242.23818\n",
      "9000 : 63648851242.23818\n",
      "Prediction for [2030]: [[132468.29612393]]\n"
     ]
    }
   ],
   "source": [
    "# implementation de la regreessionn lineaire for one feature \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def computeFunctionOneFeature(x , y ,w ,b ):\n",
    "\n",
    "    m = x.shape[0]\n",
    "\n",
    "    cost = 0.0\n",
    "\n",
    "    for i in range(m):\n",
    "\n",
    "        f_wb_i = x[i]* w + b \n",
    "\n",
    "        err = f_wb_i - y[i]\n",
    "\n",
    "        cost+= err**2\n",
    "\n",
    "    return cost \n",
    "\n",
    "def computeGradientOneFeature(x ,y , w, b):\n",
    "\n",
    "\n",
    "    dj_djw = 0.0\n",
    "    dj_db = 0.0\n",
    "\n",
    "    m = x.shape[0]\n",
    "\n",
    "    for i in range (m):\n",
    "\n",
    "        f_wb_i = x*w+b \n",
    "\n",
    "        f_wb = f_wb_i -y[i]\n",
    "\n",
    "        dj_djw += x[i]* f_wb\n",
    "\n",
    "        dj_db += f_wb\n",
    "    \n",
    "\n",
    "    return dj_djw , dj_db\n",
    "\n",
    "\n",
    "\n",
    "def gradientDestLR(x , y , w_in , b_in , alpha , numb_iterations ):\n",
    "\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    j_history = []\n",
    "\n",
    "\n",
    "    for i in range(numb_iterations):\n",
    "\n",
    "        dj_dw , dj_db = computeGradientLR(x , y ,w ,b)\n",
    "\n",
    "        cost = compute_functionLR(x ,y ,w , b)\n",
    "\n",
    "        # mise a jour des parametres \n",
    "\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha *dj_db\n",
    "\n",
    "        if i % 1000 : \n",
    "\n",
    "            j_history.append(cost)\n",
    "\n",
    "            print(f\"{i}: {cost}\")\n",
    "        \n",
    "\n",
    "    return w , b ,j_history\n",
    "\n",
    "\n",
    "def predict(x , w,b):\n",
    "\n",
    "    return  w*x + b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extract the single feature and the target\n",
    "x_train = data[['SqFt']].values  # Use only one feature\n",
    "y_train = data['Price'].values\n",
    "\n",
    "# Normalization manually\n",
    "mean = np.mean(x_train)\n",
    "std = np.std(x_train)\n",
    "x_train_scaled = (x_train - mean) / std\n",
    "\n",
    "# Initialize parameters\n",
    "w_init = np.array([0.5])  # Adjust for one feature\n",
    "b_init = 0.5\n",
    "alpha = 0.01  # Learning rate\n",
    "iterations = 10000\n",
    "\n",
    "# Train the model\n",
    "w_final, b_final, cost_hist = gradienDescentLR(x_train_scaled, y_train, w_init, b_init, alpha, iterations)\n",
    "\n",
    "# Prediction for a new example (e.g., 2030 SqFt)\n",
    "x_test = np.array([[2030]])\n",
    "\n",
    "# Normalize the test example\n",
    "x_test_scaled = (x_test - mean) / std\n",
    "y_pred = predict(x_test_scaled, w_final, b_final)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données :\n",
      "   Home   Price  SqFt  Bedrooms  Bathrooms  Offers Brick Neighborhood\n",
      "0     1  114300  1790         2          2       2    No         East\n",
      "1     2  114200  2030         4          2       3    No         East\n",
      "2     3  114800  1740         3          2       1    No         East\n",
      "3     4   94700  1980         3          2       3    No         East\n",
      "4     5  119800  2130         3          3       3    No         East\n",
      "\n",
      "Données standardisées :\n",
      "       Home     Price      SqFt  Bedrooms  Bathrooms    Offers Brick  \\\n",
      "0 -1.711845 -0.600226 -0.996999 -1.409788  -0.865538 -0.540645    No   \n",
      "1 -1.684887 -0.603948  0.137364  1.345217  -0.865538  0.394525    No   \n",
      "2 -1.657929 -0.581617 -1.233325 -0.032285  -0.865538 -1.475815    No   \n",
      "3 -1.630971 -1.329698 -0.098961 -0.032285  -0.865538  0.394525    No   \n",
      "4 -1.604013 -0.395528  0.610016 -0.032285   1.078126  0.394525    No   \n",
      "\n",
      "  Neighborhood  \n",
      "0         East  \n",
      "1         East  \n",
      "2         East  \n",
      "3         East  \n",
      "4         East  \n",
      "\n",
      "Données avec Min-Max Scaling :\n",
      "       Home     Price      SqFt  Bedrooms  Bathrooms  Offers Brick  \\\n",
      "0  0.000000  0.318086  0.298246  0.000000        0.0     0.2    No   \n",
      "1  0.007874  0.317382  0.508772  0.666667        0.0     0.4    No   \n",
      "2  0.015748  0.321605  0.254386  0.333333        0.0     0.0    No   \n",
      "3  0.023622  0.180155  0.464912  0.333333        0.0     0.4    No   \n",
      "4  0.031496  0.356791  0.596491  0.333333        0.5     0.4    No   \n",
      "\n",
      "  Neighborhood  \n",
      "0         East  \n",
      "1         East  \n",
      "2         East  \n",
      "3         East  \n",
      "4         East  \n",
      "\n",
      "Données avec MaxAbs Scaling :\n",
      "       Home     Price      SqFt  Bedrooms  Bathrooms    Offers Brick  \\\n",
      "0  0.007812  0.541193  0.691120       0.4       0.50  0.333333    No   \n",
      "1  0.015625  0.540720  0.783784       0.8       0.50  0.500000    No   \n",
      "2  0.023438  0.543561  0.671815       0.6       0.50  0.166667    No   \n",
      "3  0.031250  0.448390  0.764479       0.6       0.50  0.500000    No   \n",
      "4  0.039062  0.567235  0.822394       0.6       0.75  0.500000    No   \n",
      "\n",
      "  Neighborhood  \n",
      "0         East  \n",
      "1         East  \n",
      "2         East  \n",
      "3         East  \n",
      "4         East  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données à partir d'un fichier CSV\n",
    "data = pd.read_csv('house-prices.csv')  # Remplacez par le chemin de votre fichier\n",
    "\n",
    "# Afficher un aperçu des données\n",
    "print(\"Aperçu des données :\")\n",
    "print(data.head())\n",
    "\n",
    "# 1. Standardization (Z-score scaling)\n",
    "def standardize(data):\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "    return (data - mean) / std\n",
    "\n",
    "# 2. Min-Max Scaling\n",
    "def min_max_scale(data):\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    return (data - min_val) / (max_val - min_val)\n",
    "\n",
    "# 3. MaxAbs Scaling\n",
    "def max_abs_scale(data):\n",
    "    max_abs = data.abs().max()\n",
    "    return data / max_abs\n",
    "\n",
    "# Appliquer les méthodes de scaling à chaque colonne numérique\n",
    "scaled_data_standardized = data.copy()\n",
    "scaled_data_min_max = data.copy()\n",
    "scaled_data_max_abs = data.copy()\n",
    "\n",
    "for column in data.select_dtypes(include=[np.number]).columns:\n",
    "    scaled_data_standardized[column] = standardize(data[column])\n",
    "    scaled_data_min_max[column] = min_max_scale(data[column])\n",
    "    scaled_data_max_abs[column] = max_abs_scale(data[column])\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"\\nDonnées standardisées :\")\n",
    "print(scaled_data_standardized.head())\n",
    "\n",
    "print(\"\\nDonnées avec Min-Max Scaling :\")\n",
    "print(scaled_data_min_max.head())\n",
    "\n",
    "print(\"\\nDonnées avec MaxAbs Scaling :\")\n",
    "print(scaled_data_max_abs.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
