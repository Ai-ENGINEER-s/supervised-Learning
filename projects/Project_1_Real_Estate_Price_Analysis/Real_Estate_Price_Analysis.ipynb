{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB1 : Implementation manuelle de la regression lineaire multiple\n",
    "\n",
    "### Dans cette lab l'objectif est de coder nous meme notre modèle de la regression lineaire Multiple sans passer par une bibliothèque tierce . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 8863704678.928347\n",
      "Iteration 1000: Cost 1374661096.4474719\n",
      "Iteration 2000: Cost 373285054.99258614\n",
      "Iteration 3000: Cost 238459804.5686218\n",
      "Iteration 4000: Cost 220256290.72399595\n",
      "Iteration 5000: Cost 217795055.70822418\n",
      "Iteration 6000: Cost 217461793.4826385\n",
      "Iteration 7000: Cost 217416533.58450592\n",
      "Iteration 8000: Cost 217410341.00364435\n",
      "Iteration 9000: Cost 217409477.55370894\n",
      "Prediction for [2030    4]: [144058.29250012]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Fonction coût pour la régression linéaire (Mean Squared Error)\n",
    "def compute_cost_linear_regression(x, y, w, b):\n",
    "    m = x.shape[0]  # Nombre d'exemples d'entraînement\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b  # Prédiction pour l'exemple i\n",
    "        err = f_wb_i - y[i]  # Erreur\n",
    "        cost += err ** 2\n",
    "    cost /= (2 * m)\n",
    "    return cost \n",
    "\n",
    "# Descente de gradient pour calculer les gradients de w et b\n",
    "def compute_gradient_descent(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    n = len(w)\n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0.0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b\n",
    "        err = f_wb_i - y[i]\n",
    "        \n",
    "        for j in range(n):\n",
    "            dj_dw[j] += err * x[i, j]  # Gradient par rapport à w_j\n",
    "        dj_db += err  # Gradient par rapport à b\n",
    "\n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "    return dj_dw, dj_db\n",
    "\n",
    "# Descente de gradient pour ajuster w et b\n",
    "def linear_gradient_descent(x, y, w_in, b_in, alpha, num_iters):\n",
    "    w = copy.deepcopy(w_in)  # Copie des poids\n",
    "    b = b_in\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        # Calcul du coût actuel\n",
    "        cost = compute_cost_linear_regression(x, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Calcul des gradients\n",
    "        dj_dw, dj_db = compute_gradient_descent(x, y, w, b)\n",
    "\n",
    "        # Mise à jour des paramètres\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "\n",
    "    return w, b, cost_history\n",
    "\n",
    "# Fonction de prédiction\n",
    "def predict(x, w, b):\n",
    "    return np.dot(x, w) + b\n",
    "\n",
    "# Fonction pour normaliser manuellement les features\n",
    "def manual_normalization(x):\n",
    "    mean = np.mean(x, axis=0)  # Moyenne des colonnes\n",
    "    std = np.std(x, axis=0)  # Écart-type des colonnes\n",
    "    return (x - mean) / std, mean, std  # Retourne les données normalisées, la moyenne et l'écart-type\n",
    "\n",
    "# Lire le fichier CSV\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extraire les features et la cible\n",
    "x_train = data[['SqFt', 'Bedrooms']].values \n",
    "y_train = data.get('Price').values \n",
    "\n",
    "# Normaliser manuellement les données d'entrée (features)\n",
    "x_train_scaled, mean, std = manual_normalization(x_train)\n",
    "\n",
    "# Initialisation des paramètres\n",
    "w_init = np.array([0.5, 1])  # Ajustez en fonction du nombre de variables explicatives\n",
    "b_init = 0.5\n",
    "alpha = 0.001  # Taux d'apprentissage\n",
    "iterations = 10000\n",
    "\n",
    "# Entraînement du modèle\n",
    "w_final, b_final, cost_hist = linear_gradient_descent(x_train_scaled, y_train, w_init, b_init, alpha, iterations)\n",
    "\n",
    "# Prédiction pour un nouvel exemple (ex. 2030 SqFt, 4 chambres)\n",
    "x_test = np.array([[2030, 4]])\n",
    "\n",
    "# Normaliser manuellement l'exemple de test\n",
    "x_test_scaled = (x_test - mean) / std\n",
    "y_pred = predict(x_test_scaled, w_final, b_final)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de scikit-learn pour comparer les resultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for [2030    4]: [144059.32018322]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Lire le fichier CSV\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extraire les features et la cible\n",
    "x_train = data[['SqFt', 'Bedrooms']].values\n",
    "y_train = data['Price'].values\n",
    "\n",
    "# Normalisation des données avec scikit-learn\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Entraînement du modèle de régression linéaire avec scikit-learn\n",
    "model = LinearRegression()\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prédiction pour un nouvel exemple (ex. 2030 SqFt, 4 chambres)\n",
    "x_test = np.array([[2030, 4]])\n",
    "\n",
    "# Normalisation de l'exemple de test\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Lineaire Simple \n",
    "\n",
    "#### implementation manuelle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 8863718753.865515\n",
      "Iteration 1000: Cost 248628341.22142452\n",
      "Iteration 2000: Cost 248628325.164993\n",
      "Iteration 3000: Cost 248628325.16499305\n",
      "Iteration 4000: Cost 248628325.1649929\n",
      "Iteration 5000: Cost 248628325.1649929\n",
      "Iteration 6000: Cost 248628325.1649929\n",
      "Iteration 7000: Cost 248628325.1649929\n",
      "Iteration 8000: Cost 248628325.1649929\n",
      "Iteration 9000: Cost 248628325.1649929\n",
      "Prediction for [2030]: [132468.29612393]\n"
     ]
    }
   ],
   "source": [
    "# using one feature instead many feature linear regression manually coded : \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Cost function for linear regression (Mean Squared Error)\n",
    "def compute_cost_linear_regression(x, y, w, b):\n",
    "    m = x.shape[0]  # Number of training examples\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b  # Prediction for example i\n",
    "        err = f_wb_i - y[i]  # Error\n",
    "        cost += err ** 2\n",
    "    cost /= (2 * m)\n",
    "    return cost \n",
    "\n",
    "# Gradient descent to calculate gradients of w and b\n",
    "def compute_gradient_descent(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    dj_dw = 0.0\n",
    "    dj_db = 0.0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b\n",
    "        err = f_wb_i - y[i]\n",
    "        dj_dw += err * x[i]  # Gradient with respect to w\n",
    "        dj_db += err  # Gradient with respect to b\n",
    "\n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "    return dj_dw, dj_db\n",
    "\n",
    "# Gradient descent to adjust w and b\n",
    "def linear_gradient_descent(x, y, w_in, b_in, alpha, num_iters):\n",
    "    w = copy.deepcopy(w_in)  # Copy weights\n",
    "    b = b_in\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        # Calculate the current cost\n",
    "        cost = compute_cost_linear_regression(x, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Calculate the gradients\n",
    "        dj_dw, dj_db = compute_gradient_descent(x, y, w, b)\n",
    "\n",
    "        # Update parameters\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "\n",
    "    return w, b, cost_history\n",
    "\n",
    "# Prediction function\n",
    "def predict(x, w, b):\n",
    "    return np.dot(x, w) + b\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extract the single feature and the target\n",
    "x_train = data[['SqFt']].values  # Use only one feature\n",
    "y_train = data['Price'].values\n",
    "\n",
    "# Normalization manually\n",
    "mean = np.mean(x_train)\n",
    "std = np.std(x_train)\n",
    "x_train_scaled = (x_train - mean) / std\n",
    "\n",
    "# Initialize parameters\n",
    "w_init = np.array([0.5])  # Adjust for one feature\n",
    "b_init = 0.5\n",
    "alpha = 0.01  # Learning rate\n",
    "iterations = 10000\n",
    "\n",
    "# Train the model\n",
    "w_final, b_final, cost_hist = linear_gradient_descent(x_train_scaled, y_train, w_init, b_init, alpha, iterations)\n",
    "\n",
    "# Prediction for a new example (e.g., 2030 SqFt)\n",
    "x_test = np.array([[2030]])\n",
    "\n",
    "# Normalize the test example\n",
    "x_test_scaled = (x_test - mean) / std\n",
    "y_pred = predict(x_test_scaled, w_final, b_final)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression lineaire implemnentation avec scikit-learn pour comparer les resultats \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for [2030]: [132468.29612393]\n"
     ]
    }
   ],
   "source": [
    "# one feature using scikit-learn library \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extract the single feature and the target\n",
    "x_train = data[['SqFt']].values  # Use only one feature\n",
    "y_train = data['Price'].values\n",
    "\n",
    "# Normalization with scikit-learn\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Train the linear regression model with scikit-learn\n",
    "model = LinearRegression()\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prediction for a new example (e.g., 2030 SqFt)\n",
    "x_test = np.array([[2030]])\n",
    "\n",
    "# Normalize the test example\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
