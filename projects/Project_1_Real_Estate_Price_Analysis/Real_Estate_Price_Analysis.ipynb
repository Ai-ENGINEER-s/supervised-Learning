{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the house price according to the sqft , price , numbers of bedrooms etc \n",
    "\n",
    "import numpy as np \n",
    "import copy \n",
    "\n",
    "\n",
    "\n",
    "def compute_cost_linear_regression(x , y ,w , b):\n",
    "\n",
    "    m = x.shape[0]\n",
    "\n",
    "\n",
    "    cost = 0.0\n",
    "\n",
    "    for i in range(m):\n",
    "\n",
    "        f_wb_i = np.dot(x[i], w )+b\n",
    "\n",
    "        err = f_wb_i - y [i]\n",
    "\n",
    "        cost = cost + err **2\n",
    "\n",
    "    cost /= (2*m)\n",
    "\n",
    "\n",
    "    return cost \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_descent(x , y , w ,b):\n",
    "\n",
    "    m= x.shape[0]\n",
    "    n = len(w)\n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0.0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w )+b \n",
    "        f_wb = f_wb_i - y [i]\n",
    "\n",
    "        for j in range(n):\n",
    "\n",
    "            dj_dw[j] += f_wb * x[i,j]\n",
    "        dj_db += f_wb\n",
    "    \n",
    "    dj_dw /=m \n",
    "    dj_db /=m \n",
    "\n",
    "\n",
    "\n",
    "    return dj_dw , dj_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearGradientDescent(x , y , w_in , b_in , compute_cost_linear_regression , compute_gradient_descent, alpha , number_of_iterations): \n",
    "\n",
    "\n",
    "    \"let's compute gradient descent for linear regression \"\n",
    "\n",
    "\n",
    "    cost =0.0\n",
    "\n",
    "    w = copy.deepcopy(w_in)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(number_of_iterations):\n",
    "\n",
    "        cost = compute_cost_linear_regression(x ,y , w_in ,b_in)\n",
    "\n",
    "        dj_dw , dj_db = compute_gradient_descent(x , y ,w ,b_in)\n",
    "\n",
    "\n",
    "        # update values of parameters \n",
    "\n",
    "\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b- alpha * dj_db \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return cost , w ,b \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our multiple linear regression model \n",
    "\n",
    "def linearRegressionMultipleModel (gradientDesecent, x):\n",
    "\n",
    "    w , b, _ = gradientDesecent()\n",
    "\n",
    "    m, n = x.shape \n",
    "    prediction = 0.0\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        prediction = np.dot(x[i] , w) +b \n",
    "    \n",
    "\n",
    "    return prediction \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 4],\n",
    "    [4, 5],\n",
    "    [5, 6]\n",
    "])\n",
    "\n",
    "\n",
    "y =np.array([3, 5, 7, 9, 11]) \n",
    "\n",
    "w = np.array([0.5, 1])\n",
    "b = 0.5\n",
    "\n",
    "number_of_iterations = 10000\n",
    "\n",
    "alpha = 0.00002\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 8863704678.928347\n",
      "Iteration 1000: Cost 1374661096.4474719\n",
      "Iteration 2000: Cost 373285054.99258614\n",
      "Iteration 3000: Cost 238459804.5686218\n",
      "Iteration 4000: Cost 220256290.72399595\n",
      "Iteration 5000: Cost 217795055.70822418\n",
      "Iteration 6000: Cost 217461793.4826385\n",
      "Iteration 7000: Cost 217416533.58450592\n",
      "Iteration 8000: Cost 217410341.00364435\n",
      "Iteration 9000: Cost 217409477.55370894\n",
      "Prediction for [2030    4]: [144058.29250012]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Fonction coût pour la régression linéaire (Mean Squared Error)\n",
    "def compute_cost_linear_regression(x, y, w, b):\n",
    "    m = x.shape[0]  # Nombre d'exemples d'entraînement\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b  # Prédiction pour l'exemple i\n",
    "        err = f_wb_i - y[i]  # Erreur\n",
    "        cost += err ** 2\n",
    "    cost /= (2 * m)\n",
    "    return cost \n",
    "\n",
    "# Descente de gradient pour calculer les gradients de w et b\n",
    "def compute_gradient_descent(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    n = len(w)\n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0.0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b\n",
    "        err = f_wb_i - y[i]\n",
    "        \n",
    "        for j in range(n):\n",
    "            dj_dw[j] += err * x[i, j]  # Gradient par rapport à w_j\n",
    "        dj_db += err  # Gradient par rapport à b\n",
    "\n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "    return dj_dw, dj_db\n",
    "\n",
    "# Descente de gradient pour ajuster w et b\n",
    "def linear_gradient_descent(x, y, w_in, b_in, alpha, num_iters):\n",
    "    w = copy.deepcopy(w_in)  # Copie des poids\n",
    "    b = b_in\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        # Calcul du coût actuel\n",
    "        cost = compute_cost_linear_regression(x, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Calcul des gradients\n",
    "        dj_dw, dj_db = compute_gradient_descent(x, y, w, b)\n",
    "\n",
    "        # Mise à jour des paramètres\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "\n",
    "    return w, b, cost_history\n",
    "\n",
    "# Fonction de prédiction\n",
    "def predict(x, w, b):\n",
    "    return np.dot(x, w) + b\n",
    "\n",
    "# Fonction pour normaliser manuellement les features\n",
    "def manual_normalization(x):\n",
    "    mean = np.mean(x, axis=0)  # Moyenne des colonnes\n",
    "    std = np.std(x, axis=0)  # Écart-type des colonnes\n",
    "    return (x - mean) / std, mean, std  # Retourne les données normalisées, la moyenne et l'écart-type\n",
    "\n",
    "# Lire le fichier CSV\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extraire les features et la cible\n",
    "x_train = data[['SqFt', 'Bedrooms']].values\n",
    "y_train = data.get('Price').values \n",
    "\n",
    "# Normaliser manuellement les données d'entrée (features)\n",
    "x_train_scaled, mean, std = manual_normalization(x_train)\n",
    "\n",
    "# Initialisation des paramètres\n",
    "w_init = np.array([0.5, 1])  # Ajustez en fonction du nombre de variables explicatives\n",
    "b_init = 0.5\n",
    "alpha = 0.001  # Taux d'apprentissage\n",
    "iterations = 10000\n",
    "\n",
    "# Entraînement du modèle\n",
    "w_final, b_final, cost_hist = linear_gradient_descent(x_train_scaled, y_train, w_init, b_init, alpha, iterations)\n",
    "\n",
    "# Prédiction pour un nouvel exemple (ex. 2030 SqFt, 4 chambres)\n",
    "x_test = np.array([[2030, 4]])\n",
    "\n",
    "# Normaliser manuellement l'exemple de test\n",
    "x_test_scaled = (x_test - mean) / std\n",
    "y_pred = predict(x_test_scaled, w_final, b_final)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 8863704678.928347\n",
      "Iteration 1000: Cost 1374661096.4474719\n",
      "Iteration 2000: Cost 373285054.99258614\n",
      "Iteration 3000: Cost 238459804.5686218\n",
      "Iteration 4000: Cost 220256290.72399595\n",
      "Iteration 5000: Cost 217795055.70822418\n",
      "Iteration 6000: Cost 217461793.4826385\n",
      "Iteration 7000: Cost 217416533.58450592\n",
      "Iteration 8000: Cost 217410341.00364435\n",
      "Iteration 9000: Cost 217409477.55370894\n",
      "Prediction for [2030    4]: [144058.29250012]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Fonction coût pour la régression linéaire (Mean Squared Error)\n",
    "def compute_cost_linear_regression(x, y, w, b):\n",
    "    m = x.shape[0]  # Nombre d'exemples d'entraînement\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b  # Prédiction pour l'exemple i\n",
    "        err = f_wb_i - y[i]  # Erreur\n",
    "        cost += err ** 2\n",
    "    cost /= (2 * m)\n",
    "    return cost \n",
    "\n",
    "# Descente de gradient pour calculer les gradients de w et b\n",
    "def compute_gradient_descent(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    n = len(w)\n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0.0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b\n",
    "        err = f_wb_i - y[i]\n",
    "        \n",
    "        for j in range(n):\n",
    "            dj_dw[j] += err * x[i, j]  # Gradient par rapport à w_j\n",
    "        dj_db += err  # Gradient par rapport à b\n",
    "\n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "    return dj_dw, dj_db\n",
    "\n",
    "# Descente de gradient pour ajuster w et b\n",
    "def linear_gradient_descent(x, y, w_in, b_in, alpha, num_iters):\n",
    "    w = copy.deepcopy(w_in)  # Copie des poids\n",
    "    b = b_in\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        # Calcul du coût actuel\n",
    "        cost = compute_cost_linear_regression(x, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Calcul des gradients\n",
    "        dj_dw, dj_db = compute_gradient_descent(x, y, w, b)\n",
    "\n",
    "        # Mise à jour des paramètres\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "\n",
    "    return w, b, cost_history\n",
    "\n",
    "# Fonction de prédiction\n",
    "def predict(x, w, b):\n",
    "    return np.dot(x, w) + b\n",
    "\n",
    "# Fonction pour normaliser manuellement les features\n",
    "def manual_normalization(x):\n",
    "    mean = np.mean(x, axis=0)  # Moyenne des colonnes\n",
    "    std = np.std(x, axis=0)  # Écart-type des colonnes\n",
    "    return (x - mean) / std, mean, std  # Retourne les données normalisées, la moyenne et l'écart-type\n",
    "\n",
    "# Lire le fichier CSV\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extraire les features et la cible\n",
    "x_train = data[['SqFt', 'Bedrooms']].values\n",
    "y_train = data['Price'].values\n",
    "\n",
    "# Normaliser manuellement les données d'entrée (features)\n",
    "x_train_scaled, mean, std = manual_normalization(x_train)\n",
    "\n",
    "# Initialisation des paramètres\n",
    "w_init = np.array([0.5, 1])  # Ajustez en fonction du nombre de variables explicatives\n",
    "b_init = 0.5\n",
    "alpha = 0.001  # Taux d'apprentissage\n",
    "iterations = 10000\n",
    "\n",
    "# Entraînement du modèle\n",
    "w_final, b_final, cost_hist = linear_gradient_descent(x_train_scaled, y_train, w_init, b_init, alpha, iterations)\n",
    "\n",
    "# Prédiction pour un nouvel exemple (ex. 2030 SqFt, 4 chambres)\n",
    "x_test = np.array([[2030, 4]])\n",
    "\n",
    "# Normaliser manuellement l'exemple de test\n",
    "x_test_scaled = (x_test - mean) / std\n",
    "y_pred = predict(x_test_scaled, w_final, b_final)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction using Scikit-learn for [[6, 7]]: [13.]\n",
      "Cross-validation scores (MSE): [-7.09974815e-30 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -3.15544362e-30]\n",
      "Prediction using Ridge regression for [[6, 7]]: [12.71428571]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Données d'entraînement\n",
    "x_train = np.array([\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 4],\n",
    "    [4, 5],\n",
    "    [5, 6]\n",
    "])\n",
    "y_train = np.array([3, 5, 7, 9, 11])  # Prix des maisons\n",
    "\n",
    "# Utilisation de LinearRegression de Scikit-learn\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_sklearn = model.predict([[6, 7]])\n",
    "print(f\"Prediction using Scikit-learn for [[6, 7]]: {y_pred_sklearn}\")\n",
    "\n",
    "# Validation croisée pour vérifier la robustesse du modèle\n",
    "scores = cross_val_score(model, x_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Cross-validation scores (MSE): {scores}\")\n",
    "\n",
    "# Application de la régularisation L2 (Ridge)\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(x_train, y_train)\n",
    "y_pred_ridge = ridge_model.predict([[6, 7]])\n",
    "print(f\"Prediction using Ridge regression for [[6, 7]]: {y_pred_ridge}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for [2030    4]: [144059.32018322]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Lire le fichier CSV\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extraire les features et la cible\n",
    "x_train = data[['SqFt', 'Bedrooms']].values\n",
    "y_train = data['Price'].values\n",
    "\n",
    "# Normalisation des données avec scikit-learn\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Entraînement du modèle de régression linéaire avec scikit-learn\n",
    "model = LinearRegression()\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prédiction pour un nouvel exemple (ex. 2030 SqFt, 4 chambres)\n",
    "x_test = np.array([[2030, 4]])\n",
    "\n",
    "# Normalisation de l'exemple de test\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 8863718753.865515\n",
      "Iteration 1000: Cost 248628341.22142452\n",
      "Iteration 2000: Cost 248628325.164993\n",
      "Iteration 3000: Cost 248628325.16499305\n",
      "Iteration 4000: Cost 248628325.1649929\n",
      "Iteration 5000: Cost 248628325.1649929\n",
      "Iteration 6000: Cost 248628325.1649929\n",
      "Iteration 7000: Cost 248628325.1649929\n",
      "Iteration 8000: Cost 248628325.1649929\n",
      "Iteration 9000: Cost 248628325.1649929\n",
      "Prediction for [2030]: [132468.29612393]\n"
     ]
    }
   ],
   "source": [
    "# using one feature instead many feature linear regression manually coded : \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Cost function for linear regression (Mean Squared Error)\n",
    "def compute_cost_linear_regression(x, y, w, b):\n",
    "    m = x.shape[0]  # Number of training examples\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b  # Prediction for example i\n",
    "        err = f_wb_i - y[i]  # Error\n",
    "        cost += err ** 2\n",
    "    cost /= (2 * m)\n",
    "    return cost \n",
    "\n",
    "# Gradient descent to calculate gradients of w and b\n",
    "def compute_gradient_descent(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    dj_dw = 0.0\n",
    "    dj_db = 0.0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b\n",
    "        err = f_wb_i - y[i]\n",
    "        dj_dw += err * x[i]  # Gradient with respect to w\n",
    "        dj_db += err  # Gradient with respect to b\n",
    "\n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "    return dj_dw, dj_db\n",
    "\n",
    "# Gradient descent to adjust w and b\n",
    "def linear_gradient_descent(x, y, w_in, b_in, alpha, num_iters):\n",
    "    w = copy.deepcopy(w_in)  # Copy weights\n",
    "    b = b_in\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        # Calculate the current cost\n",
    "        cost = compute_cost_linear_regression(x, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Calculate the gradients\n",
    "        dj_dw, dj_db = compute_gradient_descent(x, y, w, b)\n",
    "\n",
    "        # Update parameters\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "\n",
    "    return w, b, cost_history\n",
    "\n",
    "# Prediction function\n",
    "def predict(x, w, b):\n",
    "    return np.dot(x, w) + b\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extract the single feature and the target\n",
    "x_train = data[['SqFt']].values  # Use only one feature\n",
    "y_train = data['Price'].values\n",
    "\n",
    "# Normalization manually\n",
    "mean = np.mean(x_train)\n",
    "std = np.std(x_train)\n",
    "x_train_scaled = (x_train - mean) / std\n",
    "\n",
    "# Initialize parameters\n",
    "w_init = np.array([0.5])  # Adjust for one feature\n",
    "b_init = 0.5\n",
    "alpha = 0.01  # Learning rate\n",
    "iterations = 10000\n",
    "\n",
    "# Train the model\n",
    "w_final, b_final, cost_hist = linear_gradient_descent(x_train_scaled, y_train, w_init, b_init, alpha, iterations)\n",
    "\n",
    "# Prediction for a new example (e.g., 2030 SqFt)\n",
    "x_test = np.array([[2030]])\n",
    "\n",
    "# Normalize the test example\n",
    "x_test_scaled = (x_test - mean) / std\n",
    "y_pred = predict(x_test_scaled, w_final, b_final)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for [2030]: [132468.29612393]\n"
     ]
    }
   ],
   "source": [
    "# one feature using scikit-learn library \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "\n",
    "# Extract the single feature and the target\n",
    "x_train = data[['SqFt']].values  # Use only one feature\n",
    "y_train = data['Price'].values\n",
    "\n",
    "# Normalization with scikit-learn\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Train the linear regression model with scikit-learn\n",
    "model = LinearRegression()\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prediction for a new example (e.g., 2030 SqFt)\n",
    "x_test = np.array([[2030]])\n",
    "\n",
    "# Normalize the test example\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "print(f\"Prediction for {x_test[0]}: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
